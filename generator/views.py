# Updated views.py - Replace the existing functions

from django.shortcuts import render
import os
from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
from django.conf import settings
from django.db.models import Count, Avg, Q  # Î ÏÎ¿ÏƒÎ¸Î­ÏƒÏ„Îµ Ï„Î¿ Avg Î±Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹
import requests
import json
import time
import logging
from .models import UserSession, PromptGeneration, PageView, TemplateUsage
from .analytics import PromptAnalyzer
from datetime import datetime, timedelta
from django.views.decorators.csrf import csrf_exempt
from django.views.decorators.http import require_http_methods
from django.utils import timezone

# Setup logging
logger = logging.getLogger(__name__)

def index(request):
    # Ensure session exists
    if not request.session.session_key:
        request.session.create()
   
    session_id = request.session.session_key
    session, created = UserSession.objects.get_or_create(
        session_id=session_id,
        defaults={'referrer': request.META.get('HTTP_REFERER', '')}
    )
   
    if not created:
        session.pages_visited += 1
        session.save()
   
    PageView.objects.create(session=session, path=request.path)
   
    # Pass ENABLE_SURVEYS to template
    context = {
        'settings': settings
    }
   
    return render(request, "generator/index.html", context)  

# NEW ENHANCED THEORY SELECTION SYSTEM

def suggest_optimal_theory(methodology, task, context):
    """
    Intelligent theory suggestion based on pedagogical context
    """
    methodology_lower = methodology.lower()
    task_lower = task.lower()
    context_lower = context.lower()
    
    # Methodology-based suggestions (highest priority)
    if any(keyword in methodology_lower for keyword in ['Î´Î¹ÎµÏÎµÏ…Î½Î·Ï„Î¹ÎºÎ®', 'ÎµÎ¾ÎµÏÎµÏÎ½Î·ÏƒÎ·', 'Î±Î½Î±ÎºÎ¬Î»Ï…ÏˆÎ·', 'Ï€ÏÏŒÎ²Î»Î·Î¼Î±']):
        return 'constructivist'
    elif any(keyword in methodology_lower for keyword in ['ÏƒÏ…Î½ÎµÏÎ³Î±Ï„Î¹ÎºÎ®', 'Î¿Î¼Î¬Î´Î±', 'Î¿Î¼Î±Î´Î¹ÎºÎ®', 'ÏƒÏ…Î½ÎµÏÎ³Î±ÏƒÎ¯Î±']):
        return 'social_learning'
    elif any(keyword in methodology_lower for keyword in ['Ï„ÎµÏ‡Î½Î¿Î»Î¿Î³Î¯Î±', 'ÏˆÎ·Ï†Î¹Î±ÎºÎ®', 'ai']):
        return 'tpack'
    elif any(keyword in methodology_lower for keyword in ['Î´Î¹Î±Ï†Î¿ÏÎ¿Ï€Î¿Î¹Î·Î¼Î­Î½Î·', 'Ï€ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÏ„Î¹ÎºÎ®', 'ÎµÎ¾Î±Ï„Î¿Î¼Î¹ÎºÎµÏ…Î¼Î­Î½Î·']):
        return 'udl'
    elif any(keyword in methodology_lower for keyword in ['Ï…Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î·', 'ÎºÎ±Î¸Î¿Î´Î®Î³Î·ÏƒÎ·', 'scaffolding']):
        return 'scaffolding'
    
    # Task-based suggestions (medium priority)
    elif any(keyword in task_lower for keyword in ['ÎºÏÎ¹Ï„Î¹ÎºÎ® ÏƒÎºÎ­ÏˆÎ·', 'ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚', 'Î±Î½Î¬Î»Ï…ÏƒÎ·']):
        return 'blooms'
    elif any(keyword in task_lower for keyword in ['Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·', 'ÎºÎ¿Ï…Î¯Î¶', 'ÏÎ¿Ï…Î¼Ï€ÏÎ¯ÎºÎ±']):
        return 'blooms'
    elif any(keyword in task_lower for keyword in ['ÏƒÏ‡Î­Î´Î¹Î¿ Î¼Î±Î¸Î®Î¼Î±Ï„Î¿Ï‚', 'Ï€Î»Î¬Î½Î¿ Î¼Î±Î¸Î®Î¼Î±Ï„Î¿Ï‚', 'Î±Î½Î±Î»Ï…Ï„Î¹ÎºÏŒ Ï€ÏÏŒÎ³ÏÎ±Î¼Î¼Î±']):
        return 'blooms'
    elif any(keyword in task_lower for keyword in ['Î´Î¹Î±Ï†Î¿ÏÎ¿Ï€Î¿Î¹Î·Î¼Î­Î½Î·', 'Ï€Î¿Î»Î»Î±Ï€Î»Î­Ï‚ Î½Î¿Î·Î¼Î¿ÏƒÏÎ½ÎµÏ‚']):
        return 'differentiation'
    
    # Context-based suggestions (lower priority)
    elif any(keyword in context_lower for keyword in ['Î¼Î¹ÎºÏ„ÏŒ ÎµÏ€Î¯Ï€ÎµÎ´Î¿', 'ÎµÎ¹Î´Î¹ÎºÎ­Ï‚ Î±Î½Î¬Î³ÎºÎµÏ‚', 'Î¼Î±Î¸Î·ÏƒÎ¹Î±ÎºÎ­Ï‚ Î´Ï…ÏƒÎºÎ¿Î»Î¯ÎµÏ‚']):
        return 'udl'
    
    # Default fallback
    return 'blooms'

def generate_blooms_enhancement(form_data):
    """Generate Bloom's Taxonomy specific enhancement"""
    task = form_data.get("task", "").lower()
    
    if any(keyword in task for keyword in ["ÎºÏÎ¹Ï„Î¹ÎºÎ® ÏƒÎºÎ­ÏˆÎ·", "ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚", "Î±Î½Î¬Î»Ï…ÏƒÎ·"]):
        return "Î”ÏŒÎ¼Î·ÏƒÎµ Ï„Î¹Ï‚ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ ÏŽÏƒÏ„Îµ Î½Î± Ï€ÏÎ¿Ï‡Ï‰ÏÎ¿ÏÎ½ Î±Ï€ÏŒ Î±Î½Î¬Î»Ï…ÏƒÎ· (Î±Î½Î¬Î»Ï…ÏƒÎ· ÎµÎ½Î½Î¿Î¹ÏŽÎ½) ÏƒÎµ Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· (ÎºÏÎ¯ÏƒÎ· Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚/Î±Î¾Î¯Î±Ï‚) ÏƒÎµ Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± (Ï€Î±ÏÎ±Î³Ï‰Î³Î® Î½Î­Ï‰Î½ Î¹Î´ÎµÏŽÎ½), Î±ÎºÎ¿Î»Î¿Ï…Î¸ÏŽÎ½Ï„Î±Ï‚ Ï„Î± Î³Î½Ï‰ÏƒÏ„Î¹ÎºÎ¬ ÎµÏ€Î¯Ï€ÎµÎ´Î± Ï„Î·Ï‚ Î¤Î±Î¾Î¹Î½Î¿Î¼Î¯Î±Ï‚ Bloom"
    elif any(keyword in task for keyword in ["Î¬ÏƒÎºÎ·ÏƒÎ·", "Î±ÏƒÎºÎ®ÏƒÎµÎ¹Ï‚", "Î´ÏÎ±ÏƒÏ„Î·ÏÎ¹ÏŒÏ„Î·Ï„ÎµÏ‚"]):
        return "Î£Ï‡ÎµÎ´Î¯Î±ÏƒÎµ Î´ÏÎ±ÏƒÏ„Î·ÏÎ¹ÏŒÏ„Î·Ï„ÎµÏ‚ Ï€Î¿Ï… ÎºÎ±Î»ÏÏ€Ï„Î¿Ï…Î½: Î¸Ï…Î¼Î¬Î¼Î±Î¹ (Î±Î½Î¬ÎºÎ»Î·ÏƒÎ· Î³ÎµÎ³Î¿Î½ÏŒÏ„Ï‰Î½) â†’ ÎºÎ±Ï„Î±Î½Î¿ÏŽ (ÎµÎ¾Î®Î³Î·ÏƒÎ· ÎµÎ½Î½Î¿Î¹ÏŽÎ½) â†’ ÎµÏ†Î±ÏÎ¼ÏŒÎ¶Ï‰ (Ï‡ÏÎ®ÏƒÎ· Î³Î½ÏŽÏƒÎ·Ï‚) â†’ Î±Î½Î±Î»ÏÏ‰ (ÎµÎ¾Î­Ï„Î±ÏƒÎ· ÏƒÏ‡Î­ÏƒÎµÏ‰Î½), Ï€ÏÎ¿Î¿Î´ÎµÏ…Ï„Î¹ÎºÎ¬ Î¼Î­ÏƒÎ± Î±Ï€ÏŒ Ï„Î·Î½ Î¤Î±Î¾Î¹Î½Î¿Î¼Î¯Î± Bloom"
    elif any(keyword in task for keyword in ["Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·", "ÎºÎ¿Ï…Î¯Î¶", "ÏÎ¿Ï…Î¼Ï€ÏÎ¯ÎºÎ±"]):
        return "Î£Ï…Î¼Ï€ÎµÏÎ¹Î­Î»Î±Î²Îµ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î± Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·Ï‚ Ï€Î¿Ï… ÎºÎ±Î»ÏÏ€Ï„Î¿Ï…Î½ Ï€Î¿Î»Î»Î±Ï€Î»Î¬ Î³Î½Ï‰ÏƒÏ„Î¹ÎºÎ¬ ÎµÏ€Î¯Ï€ÎµÎ´Î±: Î±Ï€Î¿Î¼Î½Î·Î¼ÏŒÎ½ÎµÏ…ÏƒÎ· Î²Î±ÏƒÎ¹ÎºÏŽÎ½ Î³ÎµÎ³Î¿Î½ÏŒÏ„Ï‰Î½, ÎºÎ±Ï„Î±Î½ÏŒÎ·ÏƒÎ· ÎºÏÏÎ¹Ï‰Î½ ÎµÎ½Î½Î¿Î¹ÏŽÎ½, ÎµÏ†Î±ÏÎ¼Î¿Î³Î® Î³Î½ÏŽÏƒÎ·Ï‚ ÏƒÎµ Î½Î­ÎµÏ‚ ÎºÎ±Ï„Î±ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚, ÎºÎ±Î¹ Î±Î½Î¬Î»Ï…ÏƒÎ· ÏƒÏÎ½Î¸ÎµÏ„Ï‰Î½ ÏƒÎµÎ½Î±ÏÎ¯Ï‰Î½ (Î¤Î±Î¾Î¹Î½Î¿Î¼Î¯Î± Bloom)"
    elif any(keyword in task for keyword in ["ÏƒÏ‡Î­Î´Î¹Î¿ Î¼Î±Î¸Î®Î¼Î±Ï„Î¿Ï‚", "Ï€Î»Î¬Î½Î¿ Î¼Î±Î¸Î®Î¼Î±Ï„Î¿Ï‚", "ÎµÎ¹ÏƒÎ±Î³Ï‰Î³Î®"]):
        return "Î”ÏŒÎ¼Î·ÏƒÎµ Ï„Î¿ Î¼Î¬Î¸Î·Î¼Î± ÏŽÏƒÏ„Îµ Î½Î± Ï€ÏÎ¿Ï‡Ï‰ÏÎ¬ Î¼Î­ÏƒÎ± Î±Ï€ÏŒ Î³Î½Ï‰ÏƒÏ„Î¹ÎºÎ¬ ÎµÏ€Î¯Ï€ÎµÎ´Î± Î±Ï€ÏŒ Î¸ÎµÎ¼ÎµÎ»Î¹ÏŽÎ´Î· Î³Î½ÏŽÏƒÎ· (Î¸Ï…Î¼Î¬Î¼Î±Î¹/ÎºÎ±Ï„Î±Î½Î¿ÏŽ) ÏƒÎµ ÎµÏ†Î±ÏÎ¼Î¿Î³Î® ÎºÎ±Î¹ ÏƒÎºÎ­ÏˆÎ· Ï…ÏˆÎ·Î»ÏŒÏ„ÎµÏÎ·Ï‚ Ï„Î¬Î¾Î·Ï‚ (Î±Î½Î±Î»ÏÏ‰/Î±Î¾Î¹Î¿Î»Î¿Î³ÏŽ/Î´Î·Î¼Î¹Î¿Ï…ÏÎ³ÏŽ), Î±ÎºÎ¿Î»Î¿Ï…Î¸ÏŽÎ½Ï„Î±Ï‚ Ï„Î·Î½ Î¤Î±Î¾Î¹Î½Î¿Î¼Î¯Î± Bloom"
    else:
        return "Î•Î½ÏƒÏ‰Î¼Î¬Ï„Ï‰ÏƒÎµ Î³Î½Ï‰ÏƒÏ„Î¹ÎºÎ® Ï€ÏÏŒÎ¿Î´Î¿ Î±Ï€ÏŒ Î²Î±ÏƒÎ¹ÎºÎ® Î±Î½Î¬ÎºÎ»Î·ÏƒÎ· ÏƒÎµ Î´ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚ ÏƒÎºÎ­ÏˆÎ·Ï‚ Ï…ÏˆÎ·Î»ÏŒÏ„ÎµÏÎ·Ï‚ Ï„Î¬Î¾Î·Ï‚, Î±ÎºÎ¿Î»Î¿Ï…Î¸ÏŽÎ½Ï„Î±Ï‚ Ï„Î± ÎµÏ€Î¯Ï€ÎµÎ´Î± Ï„Î·Ï‚ Î¤Î±Î¾Î¹Î½Î¿Î¼Î¯Î±Ï‚ Bloom"

def generate_udl_enhancement(form_data):
    """Generate UDL specific enhancement"""
    context = form_data.get("context", "").lower()
    
    if any(keyword in context for keyword in ["Î¼Î¹ÎºÏ„ÏŒ ÎµÏ€Î¯Ï€ÎµÎ´Î¿", "Î¼Î±Î¸Î·ÏƒÎ¹Î±ÎºÎ­Ï‚ Î´Ï…ÏƒÎºÎ¿Î»Î¯ÎµÏ‚", "ÎµÎ¹Î´Î¹ÎºÎ­Ï‚ Î±Î½Î¬Î³ÎºÎµÏ‚"]):
        return "Î Î±ÏÎ­Ï‡Îµ Ï€Î¿Î»Î»Î±Ï€Î»Î¬ Î¼Î­ÏƒÎ± Î±Î½Î±Ï€Î±ÏÎ¬ÏƒÏ„Î±ÏƒÎ·Ï‚ (Î¿Ï€Ï„Î¹ÎºÎ¬, Î±ÎºÎ¿Ï…ÏƒÏ„Î¹ÎºÎ¬, Î±Ï€Ï„Î¹ÎºÎ¬), Ï€Î¿Î»Î»Î±Ï€Î»Î¬ Î¼Î­ÏƒÎ± Î±Ï†Î¿ÏƒÎ¯Ï‰ÏƒÎ·Ï‚ (ÎµÏ€Î¹Î»Î¿Î³Î®, ÏƒÏ…Î½Î¬Ï†ÎµÎ¹Î±, ÎµÏ€Î¯Ï€ÎµÎ´Î± Ï€ÏÏŒÎºÎ»Î·ÏƒÎ·Ï‚), ÎºÎ±Î¹ Ï€Î¿Î»Î»Î±Ï€Î»Î¬ Î¼Î­ÏƒÎ± Î­ÎºÏ†ÏÎ±ÏƒÎ·Ï‚ (Ï€ÏÎ¿Ï†Î¿ÏÎ¹ÎºÎ¬, Î³ÏÎ±Ï€Ï„Î¬, ÎµÏ€Î¯Î´ÎµÎ¹Î¾Î·) Î³Î¹Î± Î½Î± Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¾ÎµÎ¹Ï‚ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¿ÏÏ‚ Î¼Î±Î¸Î·Ï„Î­Ï‚ (Î±ÏÏ‡Î­Ï‚ UDL)"
    elif any(keyword in context for keyword in ["Î´ÎµÏÏ„ÎµÏÎ· Î³Î»ÏŽÏƒÏƒÎ±", "Î¾Î­Î½Î· Î³Î»ÏŽÏƒÏƒÎ±"]):
        return "Î£Ï…Î¼Ï€ÎµÏÎ¹Î­Î»Î±Î²Îµ Î¿Ï€Ï„Î¹ÎºÎ­Ï‚ Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¾ÎµÎ¹Ï‚, Î±Ï€Î»Î¿Ï€Î¿Î¹Î·Î¼Î­Î½ÎµÏ‚ Î³Î»Ï‰ÏƒÏƒÎ¹ÎºÎ­Ï‚ ÎµÏ€Î¹Î»Î¿Î³Î­Ï‚, ÎºÎ±Î¹ Ï€Î¿Î»Î»Î±Ï€Î»Î¿ÏÏ‚ Ï„ÏÏŒÏ€Î¿Ï…Ï‚ ÎµÏ€Î¯Î´ÎµÎ¹Î¾Î·Ï‚ ÎºÎ±Ï„Î±Î½ÏŒÎ·ÏƒÎ·Ï‚ Î³Î¹Î± Î½Î± Ï†Î¹Î»Î¿Î¾ÎµÎ½Î®ÏƒÎµÎ¹Ï‚ Î¼Î±Î¸Î·Ï„Î­Ï‚ Î³Î»ÏŽÏƒÏƒÎ±Ï‚ (Î±ÏÏ‡Î­Ï‚ UDL)"
    else:
        return "Î£Ï‡ÎµÎ´Î¯Î±ÏƒÎµ Î¼Îµ ÎµÏ…ÎµÎ»Î¹Î¾Î¯Î± ÏƒÏ„Î·Î½ Ï€Î±ÏÎ¿Ï…ÏƒÎ¯Î±ÏƒÎ· Ï€ÎµÏÎ¹ÎµÏ‡Î¿Î¼Î­Î½Î¿Ï…, ÏƒÏ„Î¹Ï‚ Î¼ÎµÎ¸ÏŒÎ´Î¿Ï…Ï‚ Î±Ï†Î¿ÏƒÎ¯Ï‰ÏƒÎ·Ï‚ Î¼Î±Î¸Î·Ï„ÏŽÎ½, ÎºÎ±Î¹ ÏƒÏ„Î¹Ï‚ Î¼Î¿ÏÏ†Î­Ï‚ Î­ÎºÏ†ÏÎ±ÏƒÎ·Ï‚ Î³Î¹Î± Î½Î± Ï†Î¹Î»Î¿Î¾ÎµÎ½Î®ÏƒÎµÎ¹Ï‚ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ Î¼Î±Î¸Î·ÏƒÎ¹Î±ÎºÎ­Ï‚ Î±Î½Î¬Î³ÎºÎµÏ‚ (Î±ÏÏ‡Î­Ï‚ UDL)"

def generate_tpack_enhancement(form_data):
    """Generate TPACK specific enhancement - more specific and actionable"""
    task = form_data.get("task", "").lower()
    methodology = form_data.get("methodology", "").lower()
    subject = form_data.get("subject", "").lower()
    
    if any(keyword in task for keyword in ["ÏƒÏ‡Î­Î´Î¹Î¿ Î¼Î±Î¸Î®Î¼Î±Ï„Î¿Ï‚", "Ï€Î»Î¬Î½Î¿ Î¼Î±Î¸Î®Î¼Î±Ï„Î¿Ï‚", "Î±Î½Î±Î»Ï…Ï„Î¹ÎºÏŒ Ï€ÏÏŒÎ³ÏÎ±Î¼Î¼Î±", "Ï€Î»Î®ÏÎµÏ‚ Ï€Î»Î¬Î½Î¿"]):
        return "ÎšÎ±Î¸ÏŒÏÎ¹ÏƒÎµ ÏÎ·Ï„Î¬: (1) Ï€Î¿Î¹Î± ÎµÏÎ³Î±Î»ÎµÎ¯Î±/Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ AI Î¸Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î·Î¸Î¿ÏÎ½, (2) Ï€ÏŽÏ‚ Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¶Î¿Ï…Î½ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î¿Ï…Ï‚ Î¼Î±Î¸Î·ÏƒÎ¹Î±ÎºÎ¿ÏÏ‚ ÏƒÏ„ÏŒÏ‡Î¿Ï…Ï‚, (3) Ï€Î¿Î¹Î¿Ï‚ Ï€Î±Î¹Î´Î±Î³Ï‰Î³Î¹ÎºÏŒÏ‚ ÏÏŒÎ»Î¿Ï‚ Ï€Î±Î¯Î¶ÎµÎ¹ Î· Ï„ÎµÏ‡Î½Î¿Î»Î¿Î³Î¯Î± ÏƒÏ„Î· Î´Î¹Î´Î±ÏƒÎºÎ±Î»Î¯Î±, ÎºÎ±Î¹ (4) Ï€ÏŽÏ‚ Ï„Î± ÏˆÎ·Ï†Î¹Î±ÎºÎ¬ ÎµÏÎ³Î±Î»ÎµÎ¯Î± ÎµÎ½Î¹ÏƒÏ‡ÏÎ¿Ï…Î½ Ï„Î·Î½ ÎºÎ±Ï„Î±Î½ÏŒÎ·ÏƒÎ· Ï€ÎµÏÎ¹ÎµÏ‡Î¿Î¼Î­Î½Î¿Ï… Î±Î½Ï„Î¯ Î½Î± Î±Î½Ï„Î¹ÎºÎ±Î¸Î¹ÏƒÏ„Î¿ÏÎ½ Ï„Î· Î´Î¹Î´Î±ÏƒÎºÎ±Î»Î¯Î± (Ï€Î»Î±Î¯ÏƒÎ¹Î¿ TPACK)"
    
    elif any(keyword in task for keyword in ["Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·", "ÎºÎ¿Ï…Î¯Î¶", "ÏÎ¿Ï…Î¼Ï€ÏÎ¯ÎºÎ±"]):
        return "Î›ÎµÏ€Ï„Î¿Î¼Î­ÏÎ·ÏƒÎµ Ï€ÏŽÏ‚ Ï„Î± ÎµÏÎ³Î±Î»ÎµÎ¯Î± Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·Ï‚ Ï€Î¿Ï… ÎµÎ½Î¹ÏƒÏ‡ÏÎ¿Î½Ï„Î±Î¹ Î¼Îµ AI Î¸Î± Î¼ÎµÏ„ÏÎ®ÏƒÎ¿Ï…Î½ Ï„Î·Î½ ÎºÎ±Ï„Î±Î½ÏŒÎ·ÏƒÎ·, ÎºÎ±Î¸ÏŒÏÎ¹ÏƒÎµ Ï„Î·Î½ Ï€Î±Î¹Î´Î±Î³Ï‰Î³Î¹ÎºÎ® Î±Î¹Ï„Î¹Î¿Î»Î¿Î³Î¯Î± Î³Î¹Î± Ï„Î· Ï‡ÏÎ®ÏƒÎ· Ï„ÎµÏ‡Î½Î¿Î»Î¿Î³Î¯Î±Ï‚ ÏƒÏ„Î·Î½ Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·, ÎºÎ±Î¹ ÎµÎ¾Î®Î³Î·ÏƒÎµ Ï€ÏŽÏ‚ Î· ÏˆÎ·Ï†Î¹Î±ÎºÎ® Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· ÏƒÏ…Î½Î´Î­ÎµÏ„Î±Î¹ Î¼Îµ Ï„Î¿Ï…Ï‚ Î¼Î±Î¸Î·ÏƒÎ¹Î±ÎºÎ¿ÏÏ‚ ÏƒÏ„ÏŒÏ‡Î¿Ï…Ï‚ (Ï€Î»Î±Î¯ÏƒÎ¹Î¿ TPACK)"
    
    elif any(keyword in task for keyword in ["Î¬ÏƒÎºÎ·ÏƒÎ·", "Î±ÏƒÎºÎ®ÏƒÎµÎ¹Ï‚", "Î´ÏÎ±ÏƒÏ„Î·ÏÎ¹ÏŒÏ„Î·Ï„ÎµÏ‚"]):
        return "Î ÎµÏÎ¯Î³ÏÎ±ÏˆÎµ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î± ÎµÏÎ³Î±Î»ÎµÎ¯Î± ÎµÎ¾Î¬ÏƒÎºÎ·ÏƒÎ·Ï‚ Ï€Î¿Ï… Ï„ÏÎ¿Ï†Î¿Î´Î¿Ï„Î¿ÏÎ½Ï„Î±Î¹ Î±Ï€ÏŒ AI, ÎµÎ¾Î®Î³Î·ÏƒÎµ Ï€ÏŽÏ‚ Î· Ï„ÎµÏ‡Î½Î¿Î»Î¿Î³Î¯Î± ÎµÎ¾Î±Ï„Î¿Î¼Î¹ÎºÎµÏÎµÎ¹ Ï„Î·Î½ ÎµÎ¾Î¬ÏƒÎºÎ·ÏƒÎ·, Î»ÎµÏ€Ï„Î¿Î¼Î­ÏÎ·ÏƒÎµ Ï„Î± Ï€Î±Î¹Î´Î±Î³Ï‰Î³Î¹ÎºÎ¬ Î¿Ï†Î­Î»Î· Ï„Ï‰Î½ ÏˆÎ·Ï†Î¹Î±ÎºÏŽÎ½ Î±ÏƒÎºÎ®ÏƒÎµÏ‰Î½, ÎºÎ±Î¹ ÎºÎ±Î¸ÏŒÏÎ¹ÏƒÎµ Ï€ÏŽÏ‚ Î· Î±Î½Î±Ï„ÏÎ¿Ï†Î¿Î´ÏŒÏ„Î·ÏƒÎ· AI Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¶ÎµÎ¹ Ï„Î·Î½ Î±Î½Î¬Ï€Ï„Ï…Î¾Î· Î´ÎµÎ¾Î¹Î¿Ï„Î®Ï„Ï‰Î½ (Ï€Î»Î±Î¯ÏƒÎ¹Î¿ TPACK)"
    
    elif any(keyword in methodology for keyword in ["ai", "Ï„ÎµÏ‡Î½Î¿Î»Î¿Î³Î¯Î±", "ÏˆÎ·Ï†Î¹Î±ÎºÎ®"]):
        return "ÎšÎ±Î¸ÏŒÏÎ¹ÏƒÎµ ÏƒÎ±Ï†ÏŽÏ‚ Ï„Î¿Î½ Ï€Î±Î¹Î´Î±Î³Ï‰Î³Î¹ÎºÏŒ ÏÏŒÎ»Î¿ Ï„Î¿Ï… AI, Ï€ÏÎ¿ÏƒÎ´Î¹ÏŒÏÎ¹ÏƒÎµ Ï€ÏŽÏ‚ Î· Ï„ÎµÏ‡Î½Î¿Î»Î¿Î³Î¯Î± ÎµÎ½Î¹ÏƒÏ‡ÏÎµÎ¹ Ï„Î¹Ï‚ Î¼ÎµÎ¸ÏŒÎ´Î¿Ï…Ï‚ Î´Î¹Î´Î±ÏƒÎºÎ±Î»Î¯Î±Ï‚, ÎµÎ¾Î®Î³Î·ÏƒÎµ Ï„Î· ÏƒÏÎ½Î´ÎµÏƒÎ· Î¼ÎµÏ„Î±Î¾Ï ÏˆÎ·Ï†Î¹Î±ÎºÏŽÎ½ ÎµÏÎ³Î±Î»ÎµÎ¯Ï‰Î½ ÎºÎ±Î¹ ÎºÏ…ÏÎ¹Î±ÏÏ‡Î¯Î±Ï‚ Ï€ÎµÏÎ¹ÎµÏ‡Î¿Î¼Î­Î½Î¿Ï…, ÎºÎ±Î¹ Î´Î¹ÎºÎ±Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎµ Ï„Î¹Ï‚ Ï„ÎµÏ‡Î½Î¿Î»Î¿Î³Î¹ÎºÎ­Ï‚ ÎµÏ€Î¹Î»Î¿Î³Î­Ï‚ Î¼Îµ ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Ï„Î¹ÎºÎ® Î¸ÎµÏ‰ÏÎ¯Î± (Ï€Î»Î±Î¯ÏƒÎ¹Î¿ TPACK)"
    
    else:
        return "Î£Ï…Î¼Ï€ÎµÏÎ¹Î­Î»Î±Î²Îµ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½ÎµÏ‚ Î»ÎµÏ€Ï„Î¿Î¼Î­ÏÎµÎ¹ÎµÏ‚ Î³Î¹Î± Ï„Î¿: Ï€ÏŽÏ‚ Î· Ï„ÎµÏ‡Î½Î¿Î»Î¿Î³Î¯Î± Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¶ÎµÎ¹ Ï„Î¿Ï…Ï‚ Î¼Î±Î¸Î·ÏƒÎ¹Î±ÎºÎ¿ÏÏ‚ ÏƒÏ„ÏŒÏ‡Î¿Ï…Ï‚, Ï€Î¿Î¹Î¿Ï‚ Ï€Î±Î¹Î´Î±Î³Ï‰Î³Î¹ÎºÏŒÏ‚ ÏƒÎºÎ¿Ï€ÏŒÏ‚ ÎµÎ¾Ï…Ï€Î·ÏÎµÏ„ÎµÎ¯ Ï„Î¿ AI, ÎºÎ±Î¹ Ï€ÏŽÏ‚ Ï„Î± ÏˆÎ·Ï†Î¹Î±ÎºÎ¬ ÎµÏÎ³Î±Î»ÎµÎ¯Î± ÎµÎ½Î¹ÏƒÏ‡ÏÎ¿Ï…Î½ Î±Î½Ï„Î¯ Î½Î± Î±Î½Ï„Î¹ÎºÎ±Î¸Î¹ÏƒÏ„Î¿ÏÎ½ Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î±Ï„Î¹ÎºÎ­Ï‚ Î´Î¹Î´Î±ÎºÏ„Î¹ÎºÎ­Ï‚ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ­Ï‚ (Ï€Î»Î±Î¯ÏƒÎ¹Î¿ TPACK)"

def generate_constructivist_enhancement(form_data):
    """Generate Constructivist Learning enhancement"""
    methodology = form_data.get("methodology", "").lower()
    
    if any(keyword in methodology for keyword in ["Î´Î¹ÎµÏÎµÏ…Î½Î·Ï„Î¹ÎºÎ®", "Î±Î½Î±ÎºÎ¬Î»Ï…ÏˆÎ·", "ÎµÎ¾ÎµÏÎµÏÎ½Î·ÏƒÎ·"]):
        return "Î¥Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Îµ Ï„Î·Î½ ÎµÎ½ÎµÏÎ³Î® ÎºÎ±Ï„Î±ÏƒÎºÎµÏ…Î® Î³Î½ÏŽÏƒÎ·Ï‚ Î¼Î­ÏƒÏ‰ ÎºÎ±Î¸Î¿Î´Î·Î³Î¿ÏÎ¼ÎµÎ½Î·Ï‚ Î±Î½Î±ÎºÎ¬Î»Ï…ÏˆÎ·Ï‚, ÎµÎ½Î¸Î±ÏÏÏÎ½Î¿Î½Ï„Î±Ï‚ Ï„Î¿Ï…Ï‚ Î¼Î±Î¸Î·Ï„Î­Ï‚ Î½Î± Ï‡Ï„Î¯ÏƒÎ¿Ï…Î½ ÎºÎ±Ï„Î±Î½ÏŒÎ·ÏƒÎ· Î¼Î­ÏƒÏ‰ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ®Ï‚ ÎµÎ¾ÎµÏÎµÏÎ½Î·ÏƒÎ·Ï‚ ÎºÎ±Î¹ Î¿Ï…ÏƒÎ¹Î±ÏƒÏ„Î¹ÎºÏŽÎ½ ÏƒÏ…Î½Î´Î­ÏƒÎµÏ‰Î½ Î¼Îµ Ï€ÏÎ¿Î·Î³Î¿ÏÎ¼ÎµÎ½Î· Î³Î½ÏŽÏƒÎ·"
    elif any(keyword in methodology for keyword in ["Ï€ÏÏŒÎ²Î»Î·Î¼Î±", "Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒÏ‚ ÎºÏŒÏƒÎ¼Î¿Ï‚", "Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ­Ï‚ ÎºÎ±Ï„Î±ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚"]):
        return "Î”Î¹ÎµÏ…ÎºÏŒÎ»Ï…Î½Îµ Ï„Î· Î¼Î¬Î¸Î·ÏƒÎ· Î¼Î­ÏƒÏ‰ Î±Ï…Î¸ÎµÎ½Ï„Î¹ÎºÏŽÎ½ ÎµÎ¼Ï€ÎµÎ¹ÏÎ¹ÏŽÎ½ ÎµÏ€Î¯Î»Ï…ÏƒÎ·Ï‚ Ï€ÏÎ¿Î²Î»Î·Î¼Î¬Ï„Ï‰Î½ ÏŒÏ€Î¿Ï… Î¿Î¹ Î¼Î±Î¸Î·Ï„Î­Ï‚ ÎºÎ±Ï„Î±ÏƒÎºÎµÏ…Î¬Î¶Î¿Ï…Î½ Î³Î½ÏŽÏƒÎ· ÏƒÏ…Î½Î´Î­Î¿Î½Ï„Î±Ï‚ Î½Î­ÎµÏ‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î¼Îµ Ï…Ï€Î¬ÏÏ‡Î¿Ï…ÏƒÎ± ÎºÎ±Ï„Î±Î½ÏŒÎ·ÏƒÎ· ÎºÎ±Î¹ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ¬ Ï€Î»Î±Î¯ÏƒÎ¹Î±"
    else:
        return "Î•Î½Î¸Î¬ÏÏÏ…Î½Îµ Ï„Î·Î½ ÎµÎ½ÎµÏÎ³Î® ÎºÎ±Ï„Î±ÏƒÎºÎµÏ…Î® Î³Î½ÏŽÏƒÎ·Ï‚ Î¼Î­ÏƒÏ‰ Ï€ÏÎ±ÎºÏ„Î¹ÎºÏŽÎ½ ÎµÎ¼Ï€ÎµÎ¹ÏÎ¹ÏŽÎ½, ÏƒÏ„Î¿Ï‡Î±ÏƒÎ¼Î¿Ï, ÎºÎ±Î¹ Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î±Ï‚ ÏƒÏ…Î½Î´Î­ÏƒÎµÏ‰Î½ Î±Î½Ï„Î¯ Î³Î¹Î± Ï€Î±Î¸Î·Ï„Î¹ÎºÎ® Î»Î®ÏˆÎ· Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¹ÏŽÎ½"

def generate_social_learning_enhancement(form_data):
    """Generate Social Learning Theory enhancement"""
    methodology = form_data.get("methodology", "").lower()
    
    if any(keyword in methodology for keyword in ["ÏƒÏ…Î½ÎµÏÎ³Î±Ï„Î¹ÎºÎ®", "Î¿Î¼Î¬Î´Î±", "Î¿Î¼Î±Î´Î¹ÎºÎ®", "ÏƒÏ…Î½ÎµÏÎ³Î±ÏƒÎ¯Î±"]):
        return "Î‘Î¾Î¹Î¿Ï€Î¿Î¯Î·ÏƒÎµ Ï„Î·Î½ Î±Î»Î»Î·Î»ÎµÏ€Î¯Î´ÏÎ±ÏƒÎ· Î¼ÎµÏ„Î±Î¾Ï ÏƒÏ…Î½Î¿Î¼Î·Î»Î¯ÎºÏ‰Î½ ÎºÎ±Î¹ Ï„Î¹Ï‚ ÎµÏ…ÎºÎ±Î¹ÏÎ¯ÎµÏ‚ ÏƒÏ…Î½ÎµÏÎ³Î±Ï„Î¹ÎºÎ®Ï‚ Î¼Î¬Î¸Î·ÏƒÎ·Ï‚ ÏŒÏ€Î¿Ï… Î¿Î¹ Î¼Î±Î¸Î·Ï„Î­Ï‚ Î¼Î±Î¸Î±Î¯Î½Î¿Ï…Î½ Î¼Î­ÏƒÏ‰ Ï€Î±ÏÎ±Ï„Î®ÏÎ·ÏƒÎ·Ï‚, ÏƒÏ…Î¶Î®Ï„Î·ÏƒÎ·Ï‚, ÎºÎ±Î¹ ÎºÎ¿Î¹Î½Î®Ï‚ ÎºÎ±Ï„Î±ÏƒÎºÎµÏ…Î®Ï‚ Î³Î½ÏŽÏƒÎ·Ï‚ ÏƒÎµ ÎºÎ¿Î¹Î½Ï‰Î½Î¹ÎºÎ¬ Ï€Î»Î±Î¯ÏƒÎ¹Î±"
    elif any(keyword in methodology for keyword in ["ÏƒÏ…Î¶Î®Ï„Î·ÏƒÎ·", "Î¿Î¼Î±Î´Î¹ÎºÎ® ÎµÏÎ³Î±ÏƒÎ¯Î±"]):
        return "Î”Î·Î¼Î¹Î¿ÏÏÎ³Î·ÏƒÎµ Î´Î¿Î¼Î·Î¼Î­Î½ÎµÏ‚ ÎµÏ…ÎºÎ±Î¹ÏÎ¯ÎµÏ‚ Î³Î¹Î± ÎºÎ¿Î¹Î½Ï‰Î½Î¹ÎºÎ® Î¼Î¬Î¸Î·ÏƒÎ· Î¼Î­ÏƒÏ‰ Î¼Î¿Î½Ï„ÎµÎ»Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ Î±Ï€ÏŒ ÏƒÏ…Î½Î¿Î¼Î·Î»Î¯ÎºÎ¿Ï…Ï‚, ÏƒÏ…Î½ÎµÏÎ³Î±Ï„Î¹ÎºÎ®Ï‚ ÎµÏ€Î¯Î»Ï…ÏƒÎ·Ï‚ Ï€ÏÎ¿Î²Î»Î·Î¼Î¬Ï„Ï‰Î½, ÎºÎ±Î¹ ÎºÎ¿Î¹Î½Î¿Ï ÏƒÏ„Î¿Ï‡Î±ÏƒÎ¼Î¿Ï Î³Î¹Î± Ï„Î¹Ï‚ Î¼Î±Î¸Î·ÏƒÎ¹Î±ÎºÎ­Ï‚ Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯ÎµÏ‚"
    else:
        return "Î•Î½ÏƒÏ‰Î¼Î¬Ï„Ï‰ÏƒÎµ Î±Î»Î»Î·Î»ÎµÏ€Î¯Î´ÏÎ±ÏƒÎ· Î¼Îµ ÏƒÏ…Î½Î¿Î¼Î·Î»Î¯ÎºÎ¿Ï…Ï‚ ÎºÎ±Î¹ ÎµÏ…ÎºÎ±Î¹ÏÎ¯ÎµÏ‚ ÎºÎ¿Î¹Î½Ï‰Î½Î¹ÎºÎ®Ï‚ Î¼Î¬Î¸Î·ÏƒÎ·Ï‚ Î³Î¹Î± Î½Î± ÎµÎ½Î¹ÏƒÏ‡ÏÏƒÎµÎ¹Ï‚ Ï„Î·Î½ ÎºÎ±Ï„Î±Î½ÏŒÎ·ÏƒÎ· Î¼Î­ÏƒÏ‰ ÎºÎ¿Î¹Î½Î®Ï‚ ÎºÎ±Ï„Î±ÏƒÎºÎµÏ…Î®Ï‚ Î³Î½ÏŽÏƒÎ·Ï‚"

def generate_scaffolding_enhancement(form_data):
    """Generate Scaffolding enhancement"""
    context = form_data.get("context", "").lower()
    task = form_data.get("task", "").lower()
    
    if any(keyword in context for keyword in ["3-5", "Î½Î·Ï€Î¹Î±Î³Ï‰Î³ÎµÎ¯Î¿", "Ï€ÏÎ¿ÏƒÏ‡Î¿Î»Î¹ÎºÎ®"]):
        return "Î Î±ÏÎ­Ï‡Îµ ÎµÎºÏ„ÎµÎ½Î® Ï…Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· Î¼Îµ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î± Ï€Î±ÏÎ±Î´ÎµÎ¯Î³Î¼Î±Ï„Î±, Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ¬ Ï…Î»Î¹ÎºÎ¬, ÎºÎ±Î¹ Î²Î®Î¼Î±-Ï€ÏÎ¿Ï‚-Î²Î®Î¼Î± ÎºÎ±Î¸Î¿Î´Î®Î³Î·ÏƒÎ·, Î¼ÎµÎ¹ÏŽÎ½Î¿Î½Ï„Î±Ï‚ ÏƒÏ„Î±Î´Î¹Î±ÎºÎ¬ Ï„Î·Î½ Ï…Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· ÎºÎ±Î¸ÏŽÏ‚ Ï„Î± Ï€Î±Î¹Î´Î¹Î¬ Î±Î½Î±Ï€Ï„ÏÏƒÏƒÎ¿Ï…Î½ Î±Ï…Ï„Î¿Î½Î¿Î¼Î¯Î±"
    elif any(keyword in context for keyword in ["6-11", "Î´Î·Î¼Î¿Ï„Î¹ÎºÏŒ", "Ï€ÏÏ‰Ï„Î¿Î²Î¬Î¸Î¼Î¹Î±"]):
        return "Î£Ï…Î¼Ï€ÎµÏÎ¹Î­Î»Î±Î²Îµ Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¾ÎµÎ¹Ï‚ ÏŒÏ€Ï‰Ï‚ Î³ÏÎ±Ï†Î¹ÎºÎ¿ÏÏ‚ Î¿ÏÎ³Î±Î½Ï‰Ï„Î­Ï‚, ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¼Î­Î½Î± Ï€Î±ÏÎ±Î´ÎµÎ¯Î³Î¼Î±Ï„Î±, ÎºÎ±Î¹ ÎºÎ±Î¸Î¿Î´Î·Î³Î¿ÏÎ¼ÎµÎ½Î· ÎµÎ¾Î¬ÏƒÎºÎ·ÏƒÎ·, Î¼Îµ ÏƒÎ±Ï†Î® Î²Î®Î¼Î±Ï„Î± Ï€ÏÎ¿Ï‚ Î±Î½ÎµÎ¾Î¬ÏÏ„Î·Ï„Î· ÎµÏ†Î±ÏÎ¼Î¿Î³Î®"
    elif any(keyword in task for keyword in ["ÏƒÏÎ½Î¸ÎµÏ„Î·", "Ï€ÏÎ¿Ï‡Ï‰ÏÎ·Î¼Î­Î½Î·", "Î´ÏÏƒÎºÎ¿Î»Î·"]):
        return "Î”Î¹Î±Î¯ÏÎµÏƒÎµ ÏƒÏÎ½Î¸ÎµÏ„ÎµÏ‚ ÎµÏÎ³Î±ÏƒÎ¯ÎµÏ‚ ÏƒÎµ Î´Î¹Î±Ï‡ÎµÎ¹ÏÎ¯ÏƒÎ¹Î¼Î± Î²Î®Î¼Î±Ï„Î± Î¼Îµ Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½Î­Ï‚ Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¾ÎµÎ¹Ï‚, Î¼Î¿Î½Ï„ÎµÎ»Î¿Ï€Î¿Î¯Î·ÏƒÎ·, ÎºÎ±Î¹ ÎºÎ±Î¸Î¿Î´Î·Î³Î¿ÏÎ¼ÎµÎ½Î· ÎµÎ¾Î¬ÏƒÎºÎ·ÏƒÎ· Ï€ÏÎ¹Î½ Î±Î½Î±Î¼Î­Î½ÎµÎ¹Ï‚ Î±Î½ÎµÎ¾Î¬ÏÏ„Î·Ï„Î· ÎµÏ€Î¯Î´Î¿ÏƒÎ·"
    else:
        return "Î Î±ÏÎ­Ï‡Îµ ÎºÎ±Ï„Î¬Î»Î»Î·Î»ÎµÏ‚ Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¾ÎµÎ¹Ï‚ Ï€Î¿Ï… Î¼Ï€Î¿ÏÎ¿ÏÎ½ Î½Î± Î±Ï†Î±Î¹ÏÎµÎ¸Î¿ÏÎ½ ÏƒÏ„Î±Î´Î¹Î±ÎºÎ¬ ÎºÎ±Î¸ÏŽÏ‚ Î¿Î¹ Î¼Î±Î¸Î·Ï„Î­Ï‚ Î±Î½Î±Ï€Ï„ÏÏƒÏƒÎ¿Ï…Î½ Î¹ÎºÎ±Î½ÏŒÏ„Î·Ï„Î± ÎºÎ±Î¹ Î±Ï…Ï„Î¿Ï€ÎµÏ€Î¿Î¯Î¸Î·ÏƒÎ·"

def generate_differentiation_enhancement(form_data):
    """Generate Differentiated Instruction enhancement"""
    task = form_data.get("task", "").lower()
    
    if any(keyword in task for keyword in ["Î´Î¹Î±Ï†Î¿ÏÎ¿Ï€Î¿Î¹Î·Î¼Î­Î½Î·", "Ï€Î¿Î»Î»Î±Ï€Î»Î­Ï‚ Î½Î¿Î·Î¼Î¿ÏƒÏÎ½ÎµÏ‚"]):
        return "Î‘Ï€ÎµÏ…Î¸ÏÎ½ÏƒÎ¿Ï… ÏƒÎµ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ Î¼Î±Î¸Î·ÏƒÎ¹Î±ÎºÎ­Ï‚ Ï€ÏÎ¿Ï„Î¹Î¼Î®ÏƒÎµÎ¹Ï‚ Î¼Î­ÏƒÏ‰ Ï€Î¿Î¹ÎºÎ¯Î»Î·Ï‚ Ï€Î±ÏÎ¿Ï…ÏƒÎ¯Î±ÏƒÎ·Ï‚ Ï€ÎµÏÎ¹ÎµÏ‡Î¿Î¼Î­Î½Î¿Ï…, ÎµÏ€Î¹Î»Î¿Î³ÏŽÎ½ Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯Î±Ï‚, ÎºÎ±Î¹ ÎµÏ€Î¹Î»Î¿Î³ÏŽÎ½ Ï€ÏÎ¿ÏŠÏŒÎ½Ï„Î¿Ï‚, ÎµÏ€Î¹Ï„ÏÎ­Ï€Î¿Î½Ï„Î±Ï‚ Ï€Î¿Î»Î»Î±Ï€Î»Î­Ï‚ Î´Î¹Î±Î´ÏÎ¿Î¼Î­Ï‚ Î³Î¹Î± ÎµÏ€Î¯Î´ÎµÎ¹Î¾Î· ÎºÎ±Ï„Î±Î½ÏŒÎ·ÏƒÎ·Ï‚"
    elif any(keyword in task for keyword in ["Ï€ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÏ„Î¹ÎºÎ®", "ÎµÎ¾Î±Ï„Î¿Î¼Î¹ÎºÎµÏ…Î¼Î­Î½Î·"]):
        return "Î Î±ÏÎ­Ï‡Îµ ÎµÏ…Î­Î»Î¹ÎºÏ„ÎµÏ‚ Î¼Î±Î¸Î·ÏƒÎ¹Î±ÎºÎ­Ï‚ ÎµÏ€Î¹Î»Î¿Î³Î­Ï‚ Ï€Î¿Ï… Ï€ÏÎ¿ÏƒÎ±ÏÎ¼ÏŒÎ¶Î¿Î½Ï„Î±Î¹ ÏƒÏ„Î¹Ï‚ Î±Ï„Î¿Î¼Î¹ÎºÎ­Ï‚ Î±Î½Î¬Î³ÎºÎµÏ‚, ÎµÎ½Î´Î¹Î±Ï†Î­ÏÎ¿Î½Ï„Î±, ÎºÎ±Î¹ ÎµÏ€Î¯Ï€ÎµÎ´Î± ÎµÏ„Î¿Î¹Î¼ÏŒÏ„Î·Ï„Î±Ï‚ Ï„Ï‰Î½ Î¼Î±Î¸Î·Ï„ÏŽÎ½ Î¼Î­ÏƒÏ‰ Ï€Î¿Î¹ÎºÎ¯Î»Ï‰Î½ Î´Î¹Î´Î±ÎºÏ„Î¹ÎºÏŽÎ½ Ï€ÏÎ¿ÏƒÎµÎ³Î³Î¯ÏƒÎµÏ‰Î½"
    else:
        return "Î£Ï…Î¼Ï€ÎµÏÎ¹Î­Î»Î±Î²Îµ ÏƒÏ„ÏÎ±Ï„Î·Î³Î¹ÎºÎ­Ï‚ Î´Î¹Î±Ï†Î¿ÏÎ¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ Ï€Î¿Ï… Î±Ï€ÎµÏ…Î¸ÏÎ½Î¿Î½Ï„Î±Î¹ ÏƒÎµ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬ Î¼Î±Î¸Î·ÏƒÎ¹Î±ÎºÎ¬ ÏƒÏ„Ï…Î», Î¹ÎºÎ±Î½ÏŒÏ„Î·Ï„ÎµÏ‚, ÎºÎ±Î¹ ÎµÎ½Î´Î¹Î±Ï†Î­ÏÎ¿Î½Ï„Î± Î¼Î­ÏƒÏ‰ Ï€Î¿Î»Î»Î±Ï€Î»ÏŽÎ½ Î´Î¹Î´Î±ÎºÏ„Î¹ÎºÏŽÎ½ Ï€ÏÎ¿ÏƒÎµÎ³Î³Î¯ÏƒÎµÏ‰Î½"
# Replace the add_selected_theory_enhancement function in views.py

def add_selected_theory_enhancement(prompt, form_data, selected_theory):
    """
    Enhanced theory selection system - applies only the selected theory
    by modifying the Instructions section instead of appending at the end.
    """
    
    # Extract form data
    task = form_data.get("task", "")
    context = form_data.get("context", "")
    methodology = form_data.get("methodology", "")
    
    # If no theory selected, auto-suggest the most relevant one
    if not selected_theory:
        selected_theory = suggest_optimal_theory(methodology, task, context)
    
    # Theory enhancement mappings
    theory_enhancements = {
        'blooms': generate_blooms_enhancement(form_data),
        'udl': generate_udl_enhancement(form_data),
        'tpack': generate_tpack_enhancement(form_data),
        'constructivist': generate_constructivist_enhancement(form_data),
        'social_learning': generate_social_learning_enhancement(form_data),
        'scaffolding': generate_scaffolding_enhancement(form_data),
        'differentiation': generate_differentiation_enhancement(form_data)
    }
    
    # Apply the selected theory enhancement by modifying the Instructions
    if selected_theory in theory_enhancements:
        enhancement = theory_enhancements[selected_theory]
        if enhancement:
            # Find the Instructions section and add enhancement as instruction #7
            instructions_start = prompt.find("ÎŸÎ´Î·Î³Î¯ÎµÏ‚:")  # â† Î‘Î›Î›Î‘Î“Î—: Î•Î»Î»Î·Î½Î¹ÎºÎ¬
            if instructions_start != -1:
                # Find the end of instruction 6
                instruction_6_end = prompt.find("6. ÎšÏÎ¬Ï„Î·ÏƒÎ­ Ï„Î·Î½ ÎµÏ€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÎ® ÎºÎ±Î¹ ÎµÏƒÏ„Î¹Î±ÏƒÎ¼Î­Î½Î· ÏƒÏ„Î·Î½ ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Ï„Î¹ÎºÎ® ÎµÏÎ³Î±ÏƒÎ¯Î±")  # â† Î‘Î›Î›Î‘Î“Î—
                if instruction_6_end != -1:
                    instruction_6_end = prompt.find("\n", instruction_6_end) + 1
                    
                    # Insert the enhancement as instruction #7
                    enhancement_instruction = f"7. Î£Î—ÎœÎ‘ÎÎ¤Î™ÎšÎŸ: {enhancement}\n"  # â† Î‘Î›Î›Î‘Î“Î—: Î•Î»Î»Î·Î½Î¹ÎºÎ¬
                    
                    prompt = (prompt[:instruction_6_end] + 
                            enhancement_instruction + 
                            prompt[instruction_6_end:])
            else:
                # Fallback: if no Instructions section found, append normally
                prompt += f"\n\nÎ•ÎºÏ€Î±Î¹Î´ÎµÏ…Ï„Î¹ÎºÎ® Î•Î½Î¯ÏƒÏ‡Ï…ÏƒÎ·: {enhancement}"  # â† Î‘Î›Î›Î‘Î“Î—: Î•Î»Î»Î·Î½Î¹ÎºÎ¬
    
    return prompt, selected_theory

# UPDATED MAIN GENERATE FUNCTION

def generate_prompt(request):
    if request.method == "POST":
        start_time = time.time()
        
        try:
            data = json.loads(request.body)
            prompt = data.get("prompt", "default prompt")
            
            # Get enhancement preference and selected theory
            enhancement_type = data.get("enhancement", "enhanced")
            selected_theory = data.get("theory_enhancement", "")  # NEW: Get selected theory
            
            # Detect request type
            is_theory_request = 'educational theory expert' in prompt.lower()
            is_improvement_request = 'prompt engineering expert' in prompt.lower()
            
        except Exception as e:
            logger.error(f"JSON decode error: {e}")
            return JsonResponse({"error": "Invalid JSON"}, status=400)

        api_key = settings.GEMINI_API_KEY
        
        # Model selection based on request type
        if is_improvement_request:
            url = "https://generativelanguage.googleapis.com/v1/models/gemini-2.0-flash:generateContent?key=" + api_key
        else:
            url = "https://generativelanguage.googleapis.com/v1/models/gemini-2.5-flash:generateContent?key=" + api_key
        
        # Handle special requests
        if is_theory_request or is_improvement_request:
            if is_improvement_request:
                prompt = """You are a prompt engineering expert. Respond with ONLY valid JSON in this exact format:
{"prompt_improvements": "Your 3 numbered suggestions here..."}

Please provide exactly 3 specific improvements the user could add to their prompt to make it more effective.

Focus on the most impactful improvements like: duration/timing, output format, specificity, differentiation, assessment criteria, etc.

Do not include ```json, markdown, or any other formatting. Just pure JSON.

""" + prompt
            else:
                prompt = """You are an educational psychology expert. Respond with ONLY valid JSON in this exact format:
{"theory_explanation": "Your explanation here", "teaching_tip": "Your tip here"}

Do not include ```json, markdown, or any other formatting. Just pure JSON.

""" + prompt
        else:
            # Apply NEW ENHANCED theoretical enhancement for regular prompts
            if enhancement_type == "enhanced":
                # Extract form data for enhancement
                form_data = {
                    "role": data.get("role", ""),
                    "task": data.get("task", ""),
                    "context": data.get("context", ""),
                    "methodology": data.get("methodology", ""),
                    "subject": data.get("subject", ""),
                    "tone": data.get("tone", "")
                }
                
                # Use NEW enhancement system
                # Use NEW enhancement system
                #print(f"DEBUG: selected_theory = {selected_theory}")
                #print(f"DEBUG: enhancement_type = {enhancement_type}")
                prompt, applied_theory = add_selected_theory_enhancement(prompt, form_data, selected_theory)
                #print(f"DEBUG: applied_theory = {applied_theory}")
                #print(f"DEBUG: enhanced prompt length = {len(prompt)}")
                
                # Log which theory was applied for research purposes
                logger.info(f"Applied theory: {applied_theory} (user selected: {selected_theory})")

        # [Rest of the API call logic remains the same]
        #print(f"DEBUG: Final prompt being sent to Gemini:")
        #print(f"DEBUG: {prompt}")
        #print("="*80)
        
        # Detect large prompts (improvements applied)
        is_large_prompt = len(prompt) > 3000 or is_improvement_request
        payload = {
            "contents": [
                {
                    "parts": [
                        {"text": prompt}
                    ]
                }
            ],
            "generationConfig": {
                "temperature": 0.7,
                "topK": 40,
                "topP": 0.95,
                "maxOutputTokens": 8192 if is_large_prompt else 4096,
                "stopSequences": []
            }
        }

        logger.info(f"ðŸ“¤ Sending request to Gemini at {time.time() - start_time:.2f}s")
        
        try:
            response = requests.post(
                url, 
                json=payload, 
                timeout=30,
                headers={
                    'Content-Type': 'application/json',
                    'User-Agent': 'AI-Prompt-Generator/1.0'
                }
            )
            
            api_time = time.time() - start_time
            logger.info(f"ðŸ“¨ Got response from Gemini in {api_time:.2f}s")
            logger.info(f"ðŸ“„ Response status: {response.status_code}")
            logger.info(f"ðŸ“ Response length: {len(response.text)} chars")
            
            if response.status_code != 200:
                logger.error(f"Gemini API error: {response.status_code} - {response.text}")
                return JsonResponse({
                    "error": f"API Error: {response.status_code}",
                    "response": "Sorry, there was an error generating your prompt. Please try again."
                }, status=500)
            
        except requests.exceptions.Timeout:
            logger.error("Gemini API timeout")
            return JsonResponse({
                "error": "Request timeout", 
                "response": "The request took too long. Please try again with a shorter prompt."
            }, status=408)
        except requests.exceptions.RequestException as e:
            logger.error(f"Network error: {e}")
            return JsonResponse({
                "error": "Network error",
                "response": "Network error occurred. Please check your connection and try again."
            }, status=500)

        try:
            result = response.json()
            text_response = result["candidates"][0]["content"]["parts"][0]["text"]
            
            # Handle special requests - ensure JSON format
            if is_theory_request or is_improvement_request:
                try:
                    json.loads(text_response)
                except json.JSONDecodeError:
                    if is_improvement_request:
                        fallback_response = {
                            "prompt_improvements": text_response
                        }
                    else:
                        fallback_response = {
                            "theory_explanation": text_response,
                            "teaching_tip": "Remember to adapt this approach based on your students' individual needs."
                        }
                    text_response = json.dumps(fallback_response)
            
            total_time = time.time() - start_time
            logger.info(f"âœ… Total processing time: {total_time:.2f}s")
            
        except (KeyError, IndexError) as e:
            logger.error(f"Response parsing error: {e}")
            logger.error(f"Full response: {response.text}")
            text_response = "Sorry, no prompt was generated. Please try again."
        except Exception as e:
            logger.error(f"Unexpected parsing error: {e}")
            text_response = "Sorry, an unexpected error occurred."

        # Enhanced analytics tracking
        session_id = request.session.session_key or request.session.create()
        session, created = UserSession.objects.get_or_create(session_id=session_id)
        
        # Update template usage if template was used
        template_used = data.get("template", "")
        if template_used:
            template_obj, created = TemplateUsage.objects.get_or_create(template_name=template_used)
            template_obj.usage_count += 1
            template_obj.save()
        
        # Auto-analysis of educational data
        subject_category = PromptAnalyzer.enhanced_subject_classification(
            data.get("subject", ""),
            data.get("task", ""),
            data.get("role", ""), 
            text_response
        )
        age_group_category = PromptAnalyzer.categorize_age_group(data.get("context", ""))
        methodology_category = PromptAnalyzer.categorize_methodology(data.get("methodology", ""))
        complexity_level = PromptAnalyzer.assess_complexity(
            text_response, 
            data.get("task", ""), 
            data.get("methodology", "")
        )
        
        # Content analysis
        content_analysis = PromptAnalyzer.analyze_content(text_response)
        
        # Determine the final applied theory for analytics
        if enhancement_type == "enhanced" and not (is_theory_request or is_improvement_request):
            final_applied_theory = applied_theory
            theory_was_auto_suggested = not bool(selected_theory)
        else:
            final_applied_theory = None
            theory_was_auto_suggested = False
        
        # Create comprehensive prompt generation record with NEW THEORY TRACKING
        PromptGeneration.objects.create(
            session=session,
            template_used=template_used,
            role=data.get("role", ""),
            subject=data.get("subject", ""),
            task=data.get("task", ""),
            context=data.get("context", ""),
            methodology=data.get("methodology", ""),
            tone=data.get("tone", ""),
            enhancement_mode=enhancement_type,
            success=True,
            response_time_seconds=time.time() - start_time,
            generated_prompt=text_response,
            
            # Auto-analyzed categories
            subject_category=subject_category,
            age_group_category=age_group_category,
            methodology_category=methodology_category,
            complexity_level=complexity_level,
            
            # NEW: Theory selection tracking (will need to add these fields to model)
            selected_theory=final_applied_theory,
            theory_auto_suggested=theory_was_auto_suggested,
            
            # Content analysis results
            **content_analysis
        )
        
        return JsonResponse({"response": text_response})
    
    else:
        return JsonResponse({"error": "Only POST requests are allowed."}, status=400)

def help_page(request):
    return render(request, "generator/help.html")

@csrf_exempt
def track_copy(request):
    if request.method == "POST":
        session_id = request.session.session_key
        if session_id:
            # Find the latest prompt generation for this session
            latest_prompt = PromptGeneration.objects.filter(
                session__session_id=session_id
            ).order_by('-timestamp').first()
            
            if latest_prompt:
                latest_prompt.copied_to_clipboard = True
                latest_prompt.save()
        
        return JsonResponse({"status": "success"})
    return JsonResponse({"error": "Only POST allowed"}, status=400)

@csrf_exempt
@require_http_methods(["POST"])
def onboarding_data_collection(request):
    """
    Collect onboarding demographics data for research purposes
    
    Expected JSON payload:
    {
        "ai_experience": "none|basic|intermediate|advanced",
        "teaching_years": "0-5|6-15|16-25|25+",
        "timestamp": "ISO timestamp"
    }
    """
    if not settings.ENABLE_SURVEYS:
        return JsonResponse({
            'status': 'disabled',
            'message': 'Surveys are currently disabled'
        })
    try:
        # Parse JSON data
        data = json.loads(request.body)
        
        # Validate required fields
        ai_experience = data.get('ai_experience')
        teaching_years = data.get('teaching_years')
        
        if not ai_experience or not teaching_years:
            return JsonResponse({
                'error': 'Missing required fields',
                'required': ['ai_experience', 'teaching_years']
            }, status=400)
        
        # Server-side validation
        valid_ai_levels = ['none', 'basic', 'intermediate', 'advanced']
        valid_teaching_years = ['0-5', '6-15', '16-25', '25+']
        
        if ai_experience not in valid_ai_levels:
            return JsonResponse({
                'error': 'Invalid ai_experience value',
                'valid_values': valid_ai_levels
            }, status=400)
        
        if teaching_years not in valid_teaching_years:
            return JsonResponse({
                'error': 'Invalid teaching_years value',
                'valid_values': valid_teaching_years
            }, status=400)
        
        # Get or create session
        session_id = request.session.session_key
        if not session_id:
            request.session.create()
            session_id = request.session.session_key
        
        try:
            session = UserSession.objects.get(session_id=session_id)
        except UserSession.DoesNotExist:
            # Create new session if doesn't exist
            session = UserSession.objects.create(
                session_id=session_id,
                referrer=request.META.get('HTTP_REFERER', ''),
                user_agent=request.META.get('HTTP_USER_AGENT', '')
            )
        
        # Update demographics data
        session.ai_experience = ai_experience
        session.teaching_years = teaching_years
        session.onboarding_completed = True
        session.onboarding_completion_time = timezone.now()
        session.research_consent = True  # Implied by participation
        
        # Save with validation
        try:
            session.save()
            
            # Log for research analytics
            logger.info(f"Onboarding completed - Session: {session_id[:8]}, "
                       f"AI: {ai_experience}, Teaching: {teaching_years}")
            
            # Return success with user profile
            return JsonResponse({
                'status': 'success',
                'message': 'Demographics data saved successfully',
                'user_profile': {
                    'ai_experience': ai_experience,
                    'teaching_years': teaching_years,
                    'profile_summary': session.user_profile_summary,
                    'research_category': session.research_participant_type
                }
            })
            
        except Exception as validation_error:
            logger.error(f"Onboarding validation error: {validation_error}")
            return JsonResponse({
                'error': 'Data validation failed',
                'details': str(validation_error)
            }, status=400)
    
    except json.JSONDecodeError:
        return JsonResponse({
            'error': 'Invalid JSON format'
        }, status=400)
    
    except Exception as e:
        logger.error(f"Onboarding endpoint error: {e}")
        return JsonResponse({
            'error': 'Internal server error',
            'message': 'Please try again later'
        }, status=500)

@require_http_methods(["GET"])
def onboarding_stats(request):
    """
    Get onboarding completion statistics (for admin/research)
    """
    try:
        from django.db.models import Count, Q
        from datetime import datetime, timedelta
        
        # Basic stats
        total_sessions = UserSession.objects.count()
        completed_onboarding = UserSession.objects.filter(onboarding_completed=True).count()
        skipped_onboarding = UserSession.objects.filter(onboarding_skipped=True).count()
        
        # Demographics breakdown
        ai_experience_stats = UserSession.objects.filter(
            onboarding_completed=True
        ).values('ai_experience').annotate(count=Count('ai_experience'))
        
        teaching_years_stats = UserSession.objects.filter(
            onboarding_completed=True
        ).values('teaching_years').annotate(count=Count('teaching_years'))
        
        # Recent completions (last 7 days)
        week_ago = timezone.now() - timedelta(days=7)
        recent_completions = UserSession.objects.filter(
            onboarding_completion_time__gte=week_ago
        ).count()
        
        return JsonResponse({
            'total_sessions': total_sessions,
            'onboarding_stats': {
                'completed': completed_onboarding,
                'skipped': skipped_onboarding,
                'completion_rate': round((completed_onboarding / total_sessions * 100), 1) if total_sessions > 0 else 0,
                'recent_completions_7_days': recent_completions
            },
            'demographics_breakdown': {
                'ai_experience': list(ai_experience_stats),
                'teaching_years': list(teaching_years_stats)
            }
        })
    
    except Exception as e:
        logger.error(f"Onboarding stats error: {e}")
        return JsonResponse({
            'error': 'Unable to fetch statistics'
        }, status=500)

# Optional: Helper function to check if user needs onboarding
def user_needs_onboarding(request):
    """
    Check if current user needs to complete onboarding
    Can be used in templates or other views
    """
    session_id = request.session.session_key
    if not session_id:
        return True
    
    try:
        session = UserSession.objects.get(session_id=session_id)
        return not session.onboarding_completed
    except UserSession.DoesNotExist:
        return True

# You can also add this as a context processor if needed:
def onboarding_context(request):
    """
    Add onboarding status to template context
    Add to TEMPLATES['OPTIONS']['context_processors'] in settings.py
    """
    return {
        'needs_onboarding': user_needs_onboarding(request)
    }

# Optional: Statistics endpoint for training needs data
@require_http_methods(["GET"])
def training_needs_stats(request):
    """
    Get training needs statistics (for admin/research)
    """
    try:
        from django.db.models import Count
        from collections import Counter
        
        # Basic stats
        total_sessions = UserSession.objects.count()
        completed_training = UserSession.objects.filter(training_needs_completed=True).count()
        
        # Interest distribution
        all_interests = []
        for session in UserSession.objects.filter(training_needs_completed=True):
            all_interests.extend(session.training_interests)
        
        interest_counts = Counter(all_interests)
        
        # Priority analysis
        priority_1_areas = []
        priority_2_areas = []
        priority_3_areas = []
        
        for session in UserSession.objects.filter(training_needs_completed=True):
            for area, priority in session.training_priorities.items():
                if priority == 1:
                    priority_1_areas.append(area)
                elif priority == 2:
                    priority_2_areas.append(area)
                elif priority == 3:
                    priority_3_areas.append(area)
        
        # Research participation stats
        email_provided = UserSession.objects.filter(
            training_needs_completed=True,
            follow_up_email__isnull=False
        ).exclude(follow_up_email='').count()
        
        interview_interest = UserSession.objects.filter(
            training_needs_completed=True,
            research_interview_interest=True
        ).count()
        
        return JsonResponse({
            'total_sessions': total_sessions,
            'training_needs_stats': {
                'completed': completed_training,
                'completion_rate': round((completed_training / total_sessions * 100), 1) if total_sessions > 0 else 0,
            },
            'interest_distribution': dict(interest_counts.most_common()),
            'priority_analysis': {
                'first_priority': Counter(priority_1_areas).most_common(),
                'second_priority': Counter(priority_2_areas).most_common(),
                'third_priority': Counter(priority_3_areas).most_common(),
            },
            'research_participation': {
                'email_provided': email_provided,
                'interview_interest': interview_interest,
                'email_rate': round((email_provided / completed_training * 100), 1) if completed_training > 0 else 0
            }
        })
    
    except Exception as e:
        logger.error(f"Training needs stats error: {e}")
        return JsonResponse({
            'error': 'Unable to fetch statistics'
        }, status=500)


# Helper function to check if user needs training survey (optional utility)
def user_needs_training_survey(request):
    """
    Check if current user needs to see training needs survey
    """
    session_id = request.session.session_key
    if not session_id:
        return False
    
    try:
        session = UserSession.objects.get(session_id=session_id)
        return (session.onboarding_completed and 
                not session.training_needs_completed and 
                not session.training_needs_shown)
    except UserSession.DoesNotExist:
        return False

@csrf_exempt
@require_http_methods(["POST"])
def training_needs_data_collection(request):
    """
    Collect training needs survey data (Phase 2)
    
    Expected JSON payload:
    {
        "training_interests": ["area1", "area2", ...],
        "training_priorities": {"area1": 1, "area2": 2, "area3": 3},
        "training_other_needs": "text or null",
        "follow_up_email": "email or null",
        "research_interview_interest": true/false
    }
    """
    if not settings.ENABLE_SURVEYS:
        return JsonResponse({
            'status': 'disabled',
            'message': 'Surveys are currently disabled'
        })
    try:
        # Parse JSON data
        data = json.loads(request.body)
        
        # Validate required fields
        training_interests = data.get('training_interests', [])
        training_priorities = data.get('training_priorities', {})
        
        if not training_interests:
            return JsonResponse({
                'error': 'At least one training interest must be selected'
            }, status=400)
        
        # Get session
        session_id = request.session.session_key
        if not session_id:
            return JsonResponse({
                'error': 'No valid session found'
            }, status=400)
        
        try:
            session = UserSession.objects.get(session_id=session_id)
        except UserSession.DoesNotExist:
            return JsonResponse({
                'error': 'Session not found'
            }, status=404)
        
        # Update training needs data
        session.training_interests = training_interests
        session.training_priorities = training_priorities
        session.training_other_needs = data.get('training_other_needs')
        session.follow_up_email = data.get('follow_up_email')
        session.research_interview_interest = data.get('research_interview_interest', False)
        session.training_needs_completed = True
        session.training_needs_completion_time = timezone.now()
        
        # Save
        session.save()
        
        # Log for research analytics
        logger.info(f"Training needs completed - Session: {session_id[:8]}, "
                   f"Interests: {len(training_interests)}, Priorities: {len(training_priorities)}")
        
        return JsonResponse({
            'status': 'success',
            'message': 'Training needs data saved successfully'
        })
        
    except json.JSONDecodeError:
        return JsonResponse({
            'error': 'Invalid JSON format'
        }, status=400)
    
    except Exception as e:
        logger.error(f"Training needs endpoint error: {e}")
        return JsonResponse({
            'error': 'Internal server error',
            'message': 'Please try again later'
        }, status=500)
